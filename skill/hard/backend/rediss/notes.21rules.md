# 使用Redis，你必須知道的21個注意要點

ref https://juejin.cn/post/6942643266613411854

- 阿里的redis開發規範
- Redis開發與運維


# 使用規範

key的規範要點

- 以業務名為key前綴，用冒號隔開，以防止key衝突覆蓋。如，live:rank:1
- 確保key的語義清晰的情況下，key的長度盡量小於30個字符 ??
- key禁止包含特殊字符，如空格、換行、單雙引號以及其他轉義字符。
- Redis的key盡量設置ttl，以保證不使用的Key能被及時清理或淘汰。

value的規範要點

- value值不可以隨意設置
- 如果是String類型，單個value大小控制10k以內。
- 如果是hash、list、set、zset類型，元素個數一般不超過5000。

- 選擇適合的數據類型
- 不少小伙伴只用Redis的String類型，上來就是set和get。實際上，Redis 提供了豐富的數據結構類型，有些業務場景，更適合hash、zset等其他數據結果。

給Key設置過期時間，同時注意不同業務的key，盡量過期時間分散一點

- 因為Redis的數據是存在內存中的，而內存資源是很寶貴的。
- 我們一般是把Redis當做緩存來用，而不是數據庫，所以key的生命週期就不宜太長久啦。
- 因此，你的key，一般建議用expire設置過期時間。

如果大量的key在某個時間點集中過期，到過期的那個時間點，Redis可能會存在卡頓，甚至出現緩存雪崩現象，

因此一般不同業務的key，過期時間應該分散一些。有時候，同業務的，也可以在時間上加一個隨機值，讓過期時間分散一些。

---

建議使用批量操作提高效率

- 我們日常寫SQL的時候，都知道，批量操作效率會更高，一次更新50條，比循環50次，每次更新一條效率更高。其實Redis操作命令也是這個道理。
- Redis客戶端執行一次命令可分為4個過程：1.發送命令-> 2.命令排隊-> 3.命令執行-> 4. 返回結果。 1和4 稱為RRT（命令執行往返時間）。 Redis提供了批量操作命令，如mget、mset等，可有效節約RRT。
- 但是呢，大部分的命令，是不支持批量操作的，比如hgetall，並沒有mhgetall存在。 Pipeline 則可以解決這個問題。
- Pipeline是什麼呢?它能將一組Redis命令進行組裝，通過一次RTT傳輸給Redis，再將這組Redis命令的執行結果按順序返回給客戶端.

<img alt="" src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b865d241c02d45e7a88540ab7f70280a~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp" >


# 有坑的那些命令

慎用O(n)複雜度命令，如hgetall、smember，lrange等

- 時間複雜度為O(n)，當n持續增加時，會導致 Redis CPU 持續飆高，阻塞其他命令的執行。
- 比如hgetall，如果哈希元素n比較多的話，可以優先考慮使用hscan。

慎用Redis的monitor命令

- 因為monitor命令可能導致redis的內存持續飆升。
- 如果執行了monitor命令，Redis服務器在Monitor這個客戶端的輸出緩衝區又會有大量“存貨”，也就佔用了大量Redis內存。

生產環境不能使用 keys指令

- redis的keys是遍歷匹配的，複雜度是O（n）
- 數據庫數據越多就越慢

使用scan指令，它同keys命令一樣提供模式匹配功能。它的複雜度也是 O(n)，但是它通過游標分步進行，不會阻塞redis線程;但是會有一定的重複概率，需要在客戶端做一次去重。

舉個例子， 使用 SMEMBERS 命令可以返回集合鍵當前包含的所有元素， 但是對於 SCAN 這類增量式迭代命令來說， 因為在對鍵進行增量式迭代的過程中， 鍵可能會被修改， 所以增量式迭代命令只能對被返回的元素提供有限的保證 。

禁止使用flushall、flushdb

- Flushall 命令用於清空整個 Redis 服務器的數據(刪除所有數據庫的所有 key )。
- Flushdb 命令用於清空當前數據庫中的所有 key。

這兩命令是原子性的，不會終止執行。一旦開始執行，不會執行失敗的。

---

注意使用del命令

- 如果刪除一個String類型的key，時間複雜度就是O（1），可以直接del。
- 如果刪除一個List/Hash/Set/ZSet類型時，它的複雜度是O(n), n表示元素個數。

因此，如果你刪除一個List/Hash/Set/ZSet類型的key時，元素越多，就越慢。當n很大時，要尤其註意，會阻塞主線程的。

那麼，如果不用del，我們應該怎麼刪除呢？

- 如果是List類型，你可以執行lpop或者rpop，直到所有元素刪除完成。
- 如果是Hash/Set/ZSet類型，你可以先執行hscan/sscan/scan查詢，再執行hdel/srem/zrem依次刪除每個元素。

---

避免使用SORT、SINTER等複雜度過高的命令。

- 執行複雜度較高的命令，會消耗更多的 CPU 資源，會阻塞主線程。所以你要避免執行如SORT、SINTER、SINTERSTORE、ZUNIONSTORE、ZINTERSTORE等聚合命令，一般建議把它放到客戶端來執行。


# 項目實戰避坑操作

分佈式鎖使用的注意點

分佈式鎖其實就是，控制分佈式系統不同進程共同訪問共享資源的一種鎖的實現。秒殺下單、搶紅包等等業務場景，都需要用到分佈式鎖。我們經常使用Redis作為分佈式鎖，主要有這些注意點：

- 兩個命令SETNX + EXPIRE分開寫（典型錯誤實現範例）
  - 如果執行完setnx加鎖，正要執行expire設置過期時間時，進程crash或者要重啟維護了，那麼這個鎖就“長生不老”了，別的線程永遠獲取不到鎖啦，所以一般分佈式鎖不能這麼實現。
  - .
- SETNX + value值是過期時間 (有些小伙伴是這麼實現，有坑)
  - 這種方案的缺點：
    - 過期時間是客戶端自己生成的，分佈式環境下，每個客戶端的時間必須同步
    - 沒有保存持有者的唯一標識，可能被別的客戶端釋放/解鎖。
    - 鎖過期的時候，並發多個客戶端同時請求過來，都執行了jedis.getSet()，最終只能有一個客戶端加鎖成功，但是該客戶端鎖的過期時間，可能被別的客戶端覆蓋。 .
- SET的擴展命令（SET EX PX NX）（注意可能存在的問題）
  - 鎖過期釋放了，業務還沒執行完。
  - 鎖被別的線程誤刪。
  - .
- SET EX PX NX + 校驗唯一隨機值,再刪除（解決了誤刪問題，還是存在鎖過期，業務沒執行完的問題）
  - 在這裡，判斷是不是當前線程加的鎖和釋放鎖不是一個原子操作。如果調用jedis.del()釋放鎖的時候，可能這把鎖已經不屬於當前客戶端，會解除他人加的鎖。
  - 一般也是用lua腳本代替。
  - .
- Redisson框架 + Redlock算法 解決鎖過期釋放，業務沒執行完問題+單機問題
  - Redisson 使用了一個Watch dog解決了鎖過期釋放，業務沒執行完問題
  - 以上的分佈式鎖，還存在單機問題
    - 如果線程一在Redis的master節點上拿到了鎖，但是加鎖的key還沒同步到slave節點。恰好這時，master節點發生故障，一個slave節點就會升級為master節點。線程二就可以獲取同個key的鎖啦，但線程一也已經拿到鎖了，鎖的安全性就沒了。
    - 針對單機問題，可以使用Redlock算法。有興趣的朋友可以看下我這篇文章哈，七種方案！探討Redis分佈式鎖的正確使用姿勢
      - https://link.juejin.cn/?target=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg3NzU5NTIwNg%3D%3D%26mid%3D2247488142%26idx%3D1%26sn%3D79a304efae7a814b6f71bbbc53810c0c%26chksm%3Dcf21cda7f85644b11ff80323defb90193bc1780b45c1c6081f00da85d665fd9eb32cc934b5cf%26token%3D1120875912%26lang%3Dzh_CN%23rd
      - .
    - .
  - .
- .

---

緩存一致性注意點

- 如果是讀請求，先讀緩存，後讀數據庫
- 如果寫請求，先更新數據庫，再寫緩存
- 每次更新數據後，需要清除緩存
- 緩存一般都需要設置一定的過期失效
- 一致性要求高的話，可以使用 biglog + MQ 保證 ??
- .

並發環境下，先操作數據庫還是先操作緩存

https://link.juejin.cn/?target=https%3A%2F%2Fmp.weixin.qq.com%2Fs%3F__biz%3DMzg3NzU5NTIwNg%3D%3D%26mid%3D2247488079%26idx%3D1%26sn%3D49255f6c0c540deeb3333bcf86d6c77c%26chksm%3Dcf21cd66f856447061b5eca47f51199e120a9eaa83fa7546b4bd2667218403ccc97e726ab456%26token%3D1120875912%26lang%3Dzh_CN%23rd

---

合理評估Redis容量，避免由於頻繁set覆蓋，導致之前設置的過期時間無效

我們知道，Redis的所有數據結構類型，都是可以設置過期時間的。假設一個字符串，已經設置了過期時間，你再去重新設置它，就會導致之前的過期時間無效。

---

緩存穿透問題

- 先來看一個常見的緩存使用方式：讀請求來了，先查下緩存，緩存有值命中，就直接返回；緩存沒命中，就去查數據庫，然後把數據庫的值更新到緩存，再返回。
- 緩存穿透：指查詢一個一定不存在的數據，由於緩存是不命中時需要從數據庫查詢，查不到數據則不寫入緩存，這將導致這個不存在的數據每次請求都要到數據庫去查詢，進而給數據庫帶來壓力。
- 通俗點說，讀請求訪問時，緩存和數據庫都沒有某個值，這樣就會導致每次對這個值的查詢請求都會穿透到數據庫，這就是緩存穿透。
- .

緩存穿透一般都是這幾種情況產生的：

- 業務不合理的設計，比如大多數用戶都沒開守護，但是你的每個請求都去緩存，查詢某個userid查詢有沒有守護。
- 業務/運維/開發失誤的操作，比如緩存和數據庫的數據都被誤刪除了。
- 黑客非法請求攻擊，比如黑客故意捏造大量非法請求，以讀取不存在的業務數據。
- .

如何避免緩存穿透呢？一般有三種方法。

- 如果是非法請求，我們在API入口，對參數進行校驗，過濾非法值。
- 如果查詢數據庫為空，我們可以給緩存設置個空值，或者默認值。但是如有有寫請求進來的話，需要更新緩存哈，以保證緩存一致性，同時，最後給緩存設置適當的過期時間。 （業務上比較常用，簡單有效）
- 使用布隆過濾器快速判斷數據是否存在。即一個查詢請求過來時，先通過布隆過濾器判斷值是否存在，存在才繼續往下查。
- .

---

緩存雪奔問題

緩存雪奔： 指緩存中數據大批量到過期時間，而查詢數據量巨大，請求都直接訪問數據庫，引起數據庫壓力過大甚至down機。

- 緩存雪奔一般是由於大量數據同時過期造成的，對於這個原因，可通過均勻設置過期時間解決，即讓過期時間相對離散一點。如採用一個較大固定值+一個較小的隨機值，5小時+0到1800秒醬紫。
- Redis 故障宕機也可能引起緩存雪奔。這就需要構造Redis高可用集群啦。
- .

---

緩存擊穿問題

指熱點key在某個時間點過期的時候，而恰好在這個時間點對這個Key有大量的並發請求過來，從而大量的請求打到db

可以認為擊穿是緩存雪奔的一個子集吧。有些文章認為它倆區別，是區別在於擊穿針對某一熱點key緩存，雪奔則是很多key。

解決方案就有兩種

- 使用互斥鎖方案。緩存失效時，不是立即去加載db數據，而是先使用某些帶成功返回的原子操作命令，如(Redis的setnx）去操作，成功的時候，再去加載db數據庫數據和設置緩存。否則就去重試獲取緩存。
-  “永不過期”，是指沒有設置過期時間，但是熱點數據快要過期時，異步線程去更新和設置過期時間。
- .

---

緩存熱key問題

- 在Redis中，我們把訪問頻率高的key，稱為熱點key。如果某一熱點key的請求到服務器主機時，由於請求量特別大，可能會導致主機資源不足，甚至宕機，從而影響正常的服務。
- .
- 而熱點Key是怎麼產生的呢？主要原因有兩個
  - 用戶消費的數據遠大於生產的數據，如秒殺、熱點新聞等讀多寫少的場景。
  - 求分片集中，超過單Redi服務器的性能，比如固定名稱key，Hash落入同一台服務器，瞬間訪問量極大，超過機器瓶頸，產生熱點Key問題
  - .
- .

如何識別到熱點key呢？

- 憑經驗判斷哪些是熱Key；
- 客戶端統計上報；
- 服務代理層上報
- .

如何解決熱key問題？

- Redis集群擴容：增加分片副本，均衡讀流量；
- 對熱key進行hash散列，比如將一個key備份為key1,key2……keyN，同樣的數據N個備份，N個備份分佈到不同分片，訪問時可隨機訪問N個備份中的一個，進一步分擔讀流量；
- 使用二級緩存，即JVM本地緩存,減少Redis的讀請求。
- .



# 配置運維

使用長連接而不是短連接，並且合理配置客戶端的連接池

- 如果使用短連接，每次都需要過 TCP 三次握手、四次揮手，會增加耗時。然而長連接的話，它建立一次連接，redis的命令就能一直使用，醬紫可以減少建立redis連接時間。
- 連接池可以實現在客戶端建立多個連接並且不釋放，需要使用連接的時候，不用每次都創建連接，節省了耗時。但是需要合理設置參數，長時間不操作 Redis時，也需及時釋放連接資源。
- .

只使用 db0

- Redis Cluster 只支持 db0，要遷移的話，成本高
- .

設置maxmemory + 恰當的淘汰策略。

- 比如有些時候，業務量大起來了，redis的key被大量使用，內存直接不夠了，運維小哥哥也忘記加大內存了。難道redis直接這樣掛掉？所以需要根據實際業務，選好maxmemory-policy(最大內存淘汰策略)，設置好過期時間。

.

- 一共有8種內存淘汰策略.
  - volatile-lru：當內存不足以容納新寫入數據時，從設置了過期時間的key中使用LRU（最近最少使用）算法進行淘汰；
  - allkeys-lru：當內存不足以容納新寫入數據時，從所有key中使用LRU（最近最少使用）算法進行淘汰。
  - volatile-lfu：4.0版本新增，當內存不足以容納新寫入數據時，在過期的key中，使用LFU算法進行刪除key。
  - allkeys-lfu：4.0版本新增，當內存不足以容納新寫入數據時，從所有key中使用LFU算法進行淘汰；
  - volatile-random：當內存不足以容納新寫入數據時，從設置了過期時間的key中，隨機淘汰數據；。
  - allkeys-random：當內存不足以容納新寫入數據時，從所有key中隨機淘汰數據。
  - volatile-ttl：當內存不足以容納新寫入數據時，在設置了過期時間的key中，根據過期時間進行淘汰，越早過期的優先被淘汰；
  - noeviction：默認策略，當內存不足以容納新寫入數據時，新寫入操作會報錯
  - .
- .

---

開啟 lazy-free 機制

Redis4.0+版本支持lazy-free機制，如果你的Redis還是有bigKey這種玩意存在，建議把lazy-free開啟。當開啟它後，Redis 如果刪除一個 bigkey 時，釋放內存的耗時操作，會放到後台線程去執行，減少對主線程的阻塞影響。

---

# 阿里雲Redis開發規範

https://developer.aliyun.com/article/531067

# Redis 最佳實踐指南：7個維度+43條使用規範

https://mp.weixin.qq.com/s/2sUWnpJCvkJ8-7XSGLdesA

# 吃透了這些Redis知識點，面試官必定對你刮目相看

https://juejin.cn/post/6844903829738110989

# 這可能是最中肯的Redis規範了 ???

https://juejin.cn/post/6844903865297403918

# 一些Redis很實用的工作技巧

https://juejin.cn/post/6844904070533103630

# 當遇到美女面試官之如何理解Redis的Expire Key(過期鍵)

https://juejin.cn/post/6844903968724746254

# （四）Redis開發規範與性能優化

https://blog.csdn.net/weixin_46991815/article/details/106903297

---

阿里官方 Redis 開發規範

https://zhuanlan.zhihu.com/p/557905452

鍵值設計

1、key 名設計

可讀性和可管理性

以業務名 (或數據庫名) 為前綴(防止 key 衝突)，用冒號分隔，比如業務名: 表名: id

ugc:video:1

簡潔性

保證語義的前提下，控制 key 的長度，當 key 較多時，內存佔用也不容忽視，例如：

user:{uid}:friends:messages:{mid}簡化為u:{uid}:fr:m:{mid}

---

阿里官方 Redis 開發規範 ，很實用 ！

https://blog.51cto.com/u_15430445/5585035

---

























